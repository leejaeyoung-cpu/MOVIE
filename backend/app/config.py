"""
ì„¤ì • íŒŒì¼ - ëª¨ë“  AI/ML ê¸°ëŠ¥ í† ê¸€ ê´€ë¦¬
"""

from pydantic_settings import BaseSettings
from typing import Literal
import os

class Settings(BaseSettings):
    """
    ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •
    
    ëª¨ë“  ê³ ê¸‰ ê¸°ëŠ¥ì„ í† ê¸€ë¡œ on/off ê°€ëŠ¥
    """
    
    # ===== ê¸°ë³¸ ì„¤ì • =====
    APP_NAME: str = "Movie Review AI System"
    VERSION: str = "2.0.0"
    DEBUG: bool = True
    
    # ===== ë°ì´í„°ë² ì´ìŠ¤ =====
    DATABASE_URL: str = "sqlite:///./movie_reviews.db"
    # í”„ë¡œë•ì…˜: "postgresql://user:pass@localhost:5432/moviedb"
    
    # ===== Redis ìºì‹± =====
    REDIS_URL: str | None = None  # "redis://localhost:6379"
    ENABLE_REDIS: bool = False
    CACHE_TTL: int = 1800  # 30ë¶„
    
    # ===== ë³´ì•ˆ =====
    SECRET_KEY: str = "your-secret-key-change-this-in-production"
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    
    # ===== CORS =====
    CORS_ORIGINS: list = ["http://localhost:8501", "http://localhost:3000"]
    
    # ===== OMDb API (Open Movie Database) =====
    OMDB_API_KEY: str | None = None  # OMDb API í‚¤ (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì •)
    OMDB_BASE_URL: str = "http://www.omdbapi.com"
    ENABLE_OMDB: bool = True  # OMDb API ì‚¬ìš© ì—¬ë¶€


    
    # ==========================================
    # AI/ML ê¸°ëŠ¥ í† ê¸€ (í•µì‹¬!)
    # ==========================================
    
    # ----- GPU/CPU ì„¤ì • -----
    ENABLE_GPU: bool = True  # GPU ì‚¬ìš© (False: CPUë§Œ ì‚¬ìš©)
    GPU_DEVICE: int = 0  # GPU ë””ë°”ì´ìŠ¤ ë²ˆí˜¸
    
    # ----- ëª¨ë¸ ê²½ëŸ‰í™” -----
    ENABLE_QUANTIZATION: bool = True  # INT8 ì–‘ìí™” (4ë°° ë¹ ë¦„)
    QUANTIZATION_DTYPE: Literal["int8", "fp16", "fp32"] = "int8"
    QUANTIZATION_BACKEND: Literal["fbgemm", "qnnpack"] = "fbgemm"  # CPU: fbgemm, Mobile: qnnpack
    
    # ----- ê°ì„± ë¶„ì„ ëª¨ë¸ -----
    SENTIMENT_MODEL: Literal["kobert", "roberta", "electra", "ensemble"] = "ensemble"
    ENABLE_KNOWLEDGE_DISTILLATION: bool = True  # Teacher â†’ Student
    ENABLE_UNCERTAINTY_ESTIMATION: bool = True  # Monte Carlo Dropout
    
    # ----- Aspect-Based Sentiment Analysis -----
    ENABLE_ABSA: bool = True  # Aspect-Based ê°ì„± ë¶„ì„
    ABSA_ASPECTS: list = ["acting", "plot", "cinematography", "soundtrack", "direction", "screenplay"]
    
    # ----- Multi-Emotion Classification -----
    ENABLE_EMOTION_CLASSIFICATION: bool = True
    EMOTION_LABELS: list = ["joy", "sadness", "anger", "surprise", "fear", "disgust"]
    
    # ----- LLM Integration (ë¹„ìš© ë°œìƒ!) -----
    ENABLE_LLM: bool = False  # âš ï¸ API ë¹„ìš© ë°œìƒ
    LLM_PROVIDER: Literal["openai", "anthropic"] = "openai"
    OPENAI_API_KEY: str | None = None
    ANTHROPIC_API_KEY: str | None = None
    LLM_MODEL: str = "gpt-4-turbo-preview"  # or "claude-3-opus-20240229"
    LLM_TEMPERATURE: float = 0.7
    LLM_MAX_TOKENS: int = 500
    USE_LLM_CACHE: bool = True  # LLM ì‘ë‹µ ìºì‹±
    
    # ----- Contrastive Learning -----
    ENABLE_CONTRASTIVE_LEARNING: bool = True  # SimCSE
    
    # ----- Explainable AI -----
    ENABLE_XAI: bool = True  # LIME, SHAP
    XAI_METHOD: Literal["lime", "shap", "both"] = "both"
    
    # ==========================================
    # ì¶”ì²œ ì‹œìŠ¤í…œ ì„¤ì •
    # ==========================================
    
    RECOMMENDATION_MODEL: Literal["ncf", "svd", "gnn", "rl", "hybrid"] = "hybrid"
    
    # ----- Neural Collaborative Filtering -----
    ENABLE_NCF: bool = True
    NCF_EMBEDDING_DIM: int = 128
    NCF_LAYERS: list = [256, 128, 64, 32]
    
    # ----- Graph Neural Networks -----
    ENABLE_GNN: bool = True  # âœ… GNN í™œì„±í™”
    GNN_TYPE: Literal["graphsage", "gat", "gcn"] = "graphsage"
    GNN_HIDDEN_DIM: int = 128
    GNN_NUM_LAYERS: int = 3
    
    # ----- Sequential Recommendation -----
    ENABLE_SEQUENTIAL: bool = True
    SEQUENTIAL_MODEL: Literal["gru", "lstm", "transformer"] = "transformer"
    SEQUENCE_LENGTH: int = 50
    
    # ----- Reinforcement Learning -----
    ENABLE_RL: bool = True  # âœ… RL í™œì„±í™”
    RL_ALGORITHM: Literal["contextual_bandit", "dqn", "ppo"] = "contextual_bandit"
    RL_EPSILON: float = 0.1  # Exploration rate
    RL_LEARNING_RATE: float = 0.001
    
    # ----- Multi-Task Learning -----
    ENABLE_MULTI_TASK: bool = True
    MTL_TASKS: list = ["rating", "click", "watch_time"]
    MTL_LOSS_WEIGHTS: dict = {"rating": 0.5, "click": 0.3, "watch_time": 0.2}
    
    # ==========================================
    # ì„±ëŠ¥ ìµœì í™”
    # ==========================================
    
    # ----- ë°°ì¹˜ ì²˜ë¦¬ -----
    ENABLE_DYNAMIC_BATCHING: bool = True
    MAX_BATCH_SIZE: int = 32
    BATCH_TIMEOUT_MS: int = 100  # 100ms ë‚´ ìš”ì²­ ë¬¶ìŒ
    
    # ----- ë¹„ë™ê¸° ì²˜ë¦¬ -----
    ENABLE_ASYNC: bool = True
    WORKER_THREADS: int = 4
    
    # ----- ONNX Runtime -----
    ENABLE_ONNX: bool = True  # 2-3ë°° ë¹ ë¦„
    ONNX_OPTIMIZATION_LEVEL: Literal["all", "basic", "extended"] = "all"
    
    # ----- Feature Store -----
    ENABLE_FEATURE_STORE: bool = False
    ONLINE_STORE_TYPE: Literal["redis", "dynamodb"] = "redis"
    OFFLINE_STORE_TYPE: Literal["parquet", "delta"] = "parquet"
    
    # ==========================================
    # ê³ ê¸‰ ML ê¸°ë²•
    # ==========================================
    
    # ----- Active Learning -----
    ENABLE_ACTIVE_LEARNING: bool = True
    AL_STRATEGY: Literal["uncertainty", "query_by_committee"] = "uncertainty"
    AL_SAMPLE_SIZE: int = 100
    
    # ----- Data Augmentation -----
    ENABLE_DATA_AUGMENTATION: bool = True
    AUGMENTATION_METHODS: list = ["back_translation", "synonym_replacement", "mixup"]
    
    # ----- Semi-Supervised Learning -----
    ENABLE_SEMI_SUPERVISED: bool = True
    SSL_METHOD: Literal["pseudo_labeling", "mixmatch", "consistency"] = "pseudo_labeling"
    
    # ----- Transfer Learning -----
    ENABLE_TRANSFER_LEARNING: bool = True
    PRETRAINED_MODEL: str = "monologg/kobert"
    
    # ==========================================
    # MLOps
    # ==========================================
    
    # ----- Model Versioning -----
    ENABLE_MLFLOW: bool = False
    MLFLOW_TRACKING_URI: str | None = None
    
    # ----- A/B Testing -----
    ENABLE_AB_TESTING: bool = True
    AB_TEST_SPLIT: float = 0.5  # 50/50 split
    
    # ----- Monitoring -----
    ENABLE_MONITORING: bool = True
    SENTRY_DSN: str | None = None
    PROMETHEUS_PORT: int = 9090
    
    # ----- Drift Detection -----
    ENABLE_DRIFT_DETECTION: bool = True
    DRIFT_THRESHOLD: float = 0.05
    
    # ==========================================
    # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
    # ==========================================
    
    MODEL_DIR: str = "./models"
    SENTIMENT_MODEL_PATH: str = f"{MODEL_DIR}/sentiment"
    RECOMMENDATION_MODEL_PATH: str = f"{MODEL_DIR}/recommendation"
    GNN_MODEL_PATH: str = f"{MODEL_DIR}/gnn"
    RL_MODEL_PATH: str = f"{MODEL_DIR}/rl"
    
    class Config:
        env_file = ".env"
        case_sensitive = True


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
settings = Settings()

# Device selection moved to sentiment_analyzer.py
# def get_device():
#     """
#     ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ë°˜í™˜ (GPU/CPU)
#     """
#     if settings.ENABLE_GPU:
#         import torch
#         if torch.cuda.is_available():
#             return f"cuda:{settings.GPU_DEVICE}"
#         else:
#             print("âš ï¸  GPUê°€ í™œì„±í™”ë˜ì–´ ìˆì§€ë§Œ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
#             return "cpu"
#     return "cpu"


def get_model_config():
    """
    í˜„ì¬ í™œì„±í™”ëœ ëª¨ë¸ ì„¤ì • ìš”ì•½
    """
    device = "cpu"  # Default device
    if settings.ENABLE_GPU:
        device = f"cuda:{settings.GPU_DEVICE}"
    
    config = {
        "device": device,
        "quantization": settings.ENABLE_QUANTIZATION,
        "sentiment_model": settings.SENTIMENT_MODEL,
        "recommendation_model": settings.RECOMMENDATION_MODEL,
        "enabled_features": {
            "ABSA": settings.ENABLE_ABSA,
            "Emotion": settings.ENABLE_EMOTION_CLASSIFICATION,
            "GNN": settings.ENABLE_GNN,
            "RL": settings.ENABLE_RL,
            "LLM": settings.ENABLE_LLM,
            "XAI": settings.ENABLE_XAI,
        }
    }
    return config


def print_config():
    """
    í˜„ì¬ ì„¤ì • ì¶œë ¥ (ë””ë²„ê¹…ìš©)
    """
    print("=" * 60)
    print("ğŸ¬ Movie Review AI System Configuration")
    print("=" * 60)
    
    config = get_model_config()
    
    print(f"\nğŸ–¥ï¸  Device: {config['device']}")
    print(f"âš¡ Quantization: {'ON' if config['quantization'] else 'OFF'}")
    print(f"ğŸ§  Sentiment Model: {config['sentiment_model']}")
    print(f"ğŸ¯ Recommendation Model: {config['recommendation_model']}")
    
    print("\nâœ¨ Enabled Features:")
    for feature, enabled in config['enabled_features'].items():
        status = "âœ…" if enabled else "âŒ"
        print(f"  {status} {feature}")
    
    print("\n" + "=" * 60)


# ì•± ì‹œì‘ ì‹œ ì„¤ì • ì¶œë ¥
if __name__ == "__main__":
    print_config()
