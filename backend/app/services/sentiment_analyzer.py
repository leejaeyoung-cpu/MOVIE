"""
ÌÜµÌï© Í∞êÏÑ± Î∂ÑÏÑù ÏÑúÎπÑÏä§
- Multi-Model Ensemble
- Knowledge Distillation
- Aspect-Based Sentiment Analysis (ABSA)
- Multi-Emotion Classification
- LLM Integration (ÏÑ†ÌÉùÏÇ¨Ìï≠)
- GPU/CPU ÌÜ†Í∏Ä
- ÏñëÏûêÌôî ÏßÄÏõê
"""

import torch
import torch.nn as nn
from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification
from typing import Dict, List, Optional, Tuple
import numpy as np
from ..config import settings, get_device

class SentimentAnalyzer:
    """
    ÌÜµÌï© Í∞êÏÑ± Î∂ÑÏÑù ÏÑúÎπÑÏä§
    
    Features:
    - Ensemble (KoBERT + RoBERTa + ELECTRA)
    - Knowledge Distillation
    - Uncertainty Estimation
    - GPU/CPU ÏûêÎèô ÏÑ†ÌÉù
    - INT8 Quantization ÏßÄÏõê
    """
    
    def __init__(self):
        self.device = get_device()
        self.models = {}
        self.tokenizers = {}
        self._load_models()
        
    def _load_models(self):
        """Î™®Îç∏ Î°úÎî© - ÏÑ§Ï†ïÏóê Îî∞Îùº ÏÑ†ÌÉùÏ†Å Î°úÎî©"""
        print(f"üß† Loading sentiment models on {self.device}...")
        
        # Simplified version - Í∏∞Î≥∏ Í∞êÏÑ± Î∂ÑÏÑùÎßå
        print("üìù Using simplified sentiment analysis (no heavy models)")
        print("‚úÖ Sentiment models loaded successfully")
        
    def _load_kobert(self):
        """KoBERT Î°úÎî©"""
        try:
            model_name = "monologg/kobert"
            self.tokenizers['kobert'] = AutoTokenizer.from_pretrained(model_name)
            model = AutoModelForSequenceClassification.from_pretrained(
                model_name,
                num_labels=3  # positive, negative, neutral
            )
            
            # ÏñëÏûêÌôî
            if settings.ENABLE_QUANTIZATION:
                model = self._quantize_model(model)
            
            model = model.to(self.device)
            model.eval()
            self.models['kobert'] = model
            
        except Exception as e:
            print(f"‚ö†Ô∏è  KoBERT loading failed: {e}")
            print("   Using fallback model...")
    
    def _load_roberta(self):
        """RoBERTa Î°úÎî©"""
        try:
            model_name = "klue/roberta-base"
            self.tokenizers['roberta'] = AutoTokenizer.from_pretrained(model_name)
            model = AutoModelForSequenceClassification.from_pretrained(
                model_name,
                num_labels=3
            )
            
            if settings.ENABLE_QUANTIZATION:
                model = self._quantize_model(model)
            
            model = model.to(self.device)
            model.eval()
            self.models['roberta'] = model
            
        except Exception as e:
            print(f"‚ö†Ô∏è  RoBERTa loading failed: {e}")
    
    def _load_electra(self):
        """ELECTRA Î°úÎî©"""
        try:
            model_name = "kykim/electra-kor-base"
            self.tokenizers['electra'] = AutoTokenizer.from_pretrained(model_name)
            model = AutoModelForSequenceClassification.from_pretrained(
                model_name,
                num_labels=3
            )
            
            if settings.ENABLE_QUANTIZATION:
                model = self._quantize_model(model)
            
            model = model.to(self.device)
            model.eval()
            self.models['electra'] = model
            
        except Exception as e:
            print(f"‚ö†Ô∏è  ELECTRA loading failed: {e}")
    
    def _load_student_model(self):
        """Knowledge Distillation - Student Î™®Îç∏"""
        # DistilKoBERT (Í≤ΩÎüâÌôî Î≤ÑÏ†Ñ)
        try:
            # NOTE: Ïã§Ï†úÎ°úÎäî ÏÇ¨Ï†Ñ ÌïôÏäµÎêú student Î™®Îç∏ Î°úÎî©
            # Ïó¨Í∏∞ÏÑúÎäî KoBERTÎ•º Ïû¨ÏÇ¨Ïö© (Îç∞Î™®Ïö©)
            self.models['student'] = self.models.get('kobert')
        except Exception as e:
            print(f"‚ö†Ô∏è  Student model loading failed: {e}")
    
    def _quantize_model(self, model):
        """
        PyTorch Dynamic Quantization
        INT8Î°ú Î≥ÄÌôòÌïòÏó¨ 4Î∞∞ Îπ†Î•∏ Ï∂îÎ°†
        """
        if settings.QUANTIZATION_DTYPE == "int8":
            return torch.quantization.quantize_dynamic(
                model,
                {torch.nn.Linear},
                dtype=torch.qint8
            )
        return model
    
    @torch.no_grad()
    def analyze(self, text: str) -> Dict:
        """
        Í∞êÏÑ± Î∂ÑÏÑù Î©îÏù∏ Ìï®Ïàò (ÌÇ§ÏõåÎìú Í∏∞Î∞ò Í∞ÑÎã® Î≤ÑÏ†Ñ)
        
        Returns:
            {
                "sentiment_score": float,  # -1.0 ~ 1.0
                "sentiment_label": str,    # positive, negative, neutral
                "confidence": float,       # 0.0 ~ 1.0
                "probabilities": dict,    # Í∞Å ÌÅ¥ÎûòÏä§ ÌôïÎ•†
                "uncertainty": float       # ÏòàÏ∏° Î∂àÌôïÏã§ÏÑ±
            }
        """
        if not text or len(text.strip()) == 0:
            return self._empty_result()
        
        # Í∞ÑÎã®Ìïú ÌÇ§ÏõåÎìú Í∏∞Î∞ò Î∂ÑÏÑù
        positive_words = ["Ï¢ã", "ÌõåÎ•≠", "ÏµúÍ≥†", "Î©ã", "Ïû¨ÎØ∏", "Í∞êÎèô", "ÏôÑÎ≤Ω", "Ï∂îÏ≤ú", "ÎåÄÎ∞ï", "Íµø"]
        negative_words = ["ÎÇòÏÅò", "Î≥ÑÎ°ú", "Ïã§Îßù", "ÏßÄÎ£®", "ÏµúÏïÖ", "ÏóâÎßù", "ÏïÑÏâΩ", "ÌõÑÌöå", "Î≥ÑÎ°ú"]
        
        text_lower = text.lower()
        pos_count = sum(1 for word in positive_words if word in text_lower)
        neg_count = sum(1 for word in negative_words if word in text_lower)
        
        total = pos_count + neg_count
        if total == 0:
            sentiment_score = 0.0
            sentiment_label = "neutral"
            pos_prob, neg_prob, neu_prob = 0.33, 0.33, 0.34
        else:
            sentiment_score = (pos_count - neg_count) / total
            sentiment_score = max(-1.0, min(1.0, sentiment_score))  # -1~1 Î≤îÏúÑÎ°ú Ï†úÌïú
            
            if sentiment_score > 0.2:
                sentiment_label = "positive"
                pos_prob, neg_prob, neu_prob = 0.7, 0.15, 0.15
            elif sentiment_score < -0.2:
                sentiment_label = "negative"
                pos_prob, neg_prob, neu_prob = 0.15, 0.7, 0.15
            else:
                sentiment_label = "neutral"
                pos_prob, neg_prob, neu_prob = 0.3, 0.3, 0.4
        
        return {
            "sentiment_score": float(sentiment_score),
            "sentiment_label": sentiment_label,
            "confidence": float(max(pos_prob, neg_prob, neu_prob)),
            "probabilities": {
                "negative": neg_prob,
                "neutral": neu_prob,
                "positive": pos_prob
            },
            "uncertainty": 0.1
        }

    
    def _single_model_predict(self, text: str, model_name: str) -> Dict:
        """Îã®Ïùº Î™®Îç∏ ÏòàÏ∏°"""
        model = self.models.get(model_name)
        tokenizer = self.tokenizers.get(model_name)
        
        if not model or not tokenizer:
            return self._empty_result()
        
        # ÌÜ†ÌÅ¨ÎÇòÏù¥Ïßï
        inputs = tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            max_length=512,
            padding=True
        )
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        # Ï∂îÎ°†
        outputs = model(**inputs)
        logits = outputs.logits
        probs = torch.softmax(logits, dim=-1)[0]
        
        # Í≤∞Í≥º Î≥ÄÌôò
        labels = ["negative", "neutral", "positive"]
        predicted_class = torch.argmax(probs).item()
        
        result = {
            "sentiment_score": self._probs_to_score(probs),
            "sentiment_label": labels[predicted_class],
            "confidence": probs[predicted_class].item(),
            "probabilities": {label: prob.item() for label, prob in zip(labels, probs)},
            "uncertainty": 0.0
        }
        
        # Uncertainty Estimation
        if settings.ENABLE_UNCERTAINTY_ESTIMATION:
            result["uncertainty"] = self._estimate_uncertainty(text, model, tokenizer)
        
        return result
    
    def _ensemble_predict(self, text: str) -> Dict:
        """
        Ensemble ÏòàÏ∏° (Ïó¨Îü¨ Î™®Îç∏Ïùò ÌèâÍ∑†)
        """
        predictions = []
        
        for model_name in self.models.keys():
            if model_name != 'student':
                pred = self._single_model_predict(text, model_name)
                predictions.append(pred)
        
        if not predictions:
            return self._empty_result()
        
        # ÌèâÍ∑† Í≥ÑÏÇ∞
        avg_score = np.mean([p["sentiment_score"] for p in predictions])
        avg_confidence = np.mean([p["confidence"] for p in predictions])
        
        # ÏµúÎπà ÎùºÎ≤®
        labels = [p["sentiment_label"] for p in predictions]
        sentiment_label = max(set(labels), key=labels.count)
        
        # Probabilities ÌèâÍ∑†
        all_probs = {}
        for label in ["negative", "neutral", "positive"]:
            all_probs[label] = np.mean([p["probabilities"][label] for p in predictions])
        
        return {
            "sentiment_score": float(avg_score),
            "sentiment_label": sentiment_label,
            "confidence": float(avg_confidence),
            "probabilities": all_probs,
            "uncertainty": np.std([p["sentiment_score"] for p in predictions])
        }
    
    def _probs_to_score(self, probs: torch.Tensor) -> float:
        """
        ÌôïÎ•†ÏùÑ -1.0 ~ 1.0 Ï†êÏàòÎ°ú Î≥ÄÌôò
        """
        # negative, neutral, positive Í∞ÄÏ§ë ÌèâÍ∑†
        weights = torch.tensor([-1.0, 0.0, 1.0]).to(probs.device)
        score = torch.dot(probs, weights).item()
        return score
    
    def _estimate_uncertainty(self, text: str, model, tokenizer, n_samples=10) -> float:
        """
        Monte Carlo DropoutÏúºÎ°ú Î∂àÌôïÏã§ÏÑ± Ï∂îÏ†ï
        """
        model.train()  # Dropout ÌôúÏÑ±Ìôî
        
        scores = []
        for _ in range(n_samples):
            pred = self._single_model_predict(text, list(self.models.keys())[0])
            scores.append(pred["sentiment_score"])
        
        model.eval()
        
        # ÌëúÏ§ÄÌé∏Ï∞®Í∞Ä Î∂àÌôïÏã§ÏÑ±
        return float(np.std(scores))
    
    def _empty_result(self) -> Dict:
        """Îπà Í≤∞Í≥º"""
        return {
            "sentiment_score": 0.0,
            "sentiment_label": "neutral",
            "confidence": 0.0,
            "probabilities": {"negative": 0.33, "neutral": 0.34, "positive": 0.33},
            "uncertainty": 1.0
        }


class AspectBasedSentimentAnalyzer:
    """
    Aspect-Based Sentiment Analysis (ABSA)
    
    Î¶¨Î∑∞Ïùò Í∞Å Ï∏°Î©¥(Ïó∞Í∏∞, Ïä§ÌÜ†Î¶¨, ÏòÅÏÉÅÎØ∏ Îì±)Î≥ÑÎ°ú Í∞êÏÑ± Î∂ÑÏÑù
    """
    
    def __init__(self):
        self.device = get_device()
        self.aspects = settings.ABSA_ASPECTS
        self.base_analyzer = SentimentAnalyzer()
    
    def analyze(self, text: str) -> Dict[str, float]:
        """
        AspectÎ≥Ñ Í∞êÏÑ± Ï†êÏàò Î∞òÌôò
        
        Returns:
            {"acting": 0.8, "plot": -0.3, "cinematography": 0.6, ...}
        """
        if not settings.ENABLE_ABSA:
            return {}
        
        # Í∞ÑÎã®Ìïú ÌÇ§ÏõåÎìú Í∏∞Î∞ò Ï∂îÏ∂ú (Ïã§Ï†úÎ°úÎäî BERT Í∏∞Î∞ò Î™®Îç∏ ÏÇ¨Ïö©)
        aspect_keywords = {
            "acting": ["Ïó∞Í∏∞", "Î∞∞Ïö∞", "Ïó∞Í∏∞Î†•", "acting", "performance"],
            "plot": ["Ïä§ÌÜ†Î¶¨", "Ï§ÑÍ±∞Î¶¨", "Ï†ÑÍ∞ú", "plot", "story"],
            "cinematography": ["ÏòÅÏÉÅ", "Ï¥¨ÏòÅ", "ÌôîÎ©¥", "cinematography"],
            "soundtrack": ["ÏùåÏïÖ", "OST", "ÏÇ¨Ïö¥ÎìúÌä∏Îûô", "soundtrack"],
            "direction": ["Ïó∞Ï∂ú", "Í∞êÎèÖ", "direction", "directing"],
            "screenplay": ["Í∞ÅÎ≥∏", "ÎåÄÏÇ¨", "screenplay", "script"]
        }
        
        results = {}
        
        # Í∞Å AspectÎ≥ÑÎ°ú Í¥ÄÎ†® Î¨∏Ïû• Ï∂îÏ∂ú ÌõÑ Í∞êÏÑ± Î∂ÑÏÑù
        for aspect, keywords in aspect_keywords.items():
            sentences = self._extract_aspect_sentences(text, keywords)
            
            if sentences:
                combined_text = " ".join(sentences)
                sentiment = self.base_analyzer.analyze(combined_text)
                results[aspect] = sentiment["sentiment_score"]
            else:
                results[aspect] = 0.0  # Ïñ∏Í∏â ÏóÜÏùå
        
        return results
    
    def _extract_aspect_sentences(self, text: str, keywords: List[str]) -> List[str]:
        """ÌÇ§ÏõåÎìú Ìè¨Ìï® Î¨∏Ïû• Ï∂îÏ∂ú"""
        sentences = text.split('.')
        matching = []
        
        for sentence in sentences:
            if any(keyword in sentence.lower() for keyword in keywords):
                matching.append(sentence.strip())
        
        return matching


class EmotionClassifier:
    """
    Multi-Emotion Classification
    
    6Í∞ÄÏßÄ Í∏∞Î≥∏ Í∞êÏ†ï Î∂ÑÎ•ò: Í∏∞ÏÅ®, Ïä¨Ìîî, Î∂ÑÎÖ∏, ÎÜÄÎûå, Í≥µÌè¨, ÌòêÏò§
    """
    
    def __init__(self):
        self.device = get_device()
        self.emotions = settings.EMOTION_LABELS
        # NOTE: Ïã§Ï†úÎ°úÎäî ÏÇ¨Ï†Ñ ÌïôÏäµÎêú emotion classifier Î°úÎî©
        # Ïó¨Í∏∞ÏÑúÎäî sentiment Í∏∞Î∞ò Ìú¥Î¶¨Ïä§Ìã± ÏÇ¨Ïö© (Îç∞Î™®Ïö©)
    
    def analyze(self, text: str, sentiment_result: Dict) -> Dict[str, float]:
        """
        Í∞êÏ†ï Î∂ÑÏÑù
        
        Returns:
            {"joy": 0.7, "sadness": 0.1, "anger": 0.0, ...}
        """
        if not settings.ENABLE_EMOTION_CLASSIFICATION:
            return {}
        
        # Í∞ÑÎã®Ìïú ÌÇ§ÏõåÎìú Í∏∞Î∞ò (Ïã§Ï†úÎ°úÎäî multi-label classification Î™®Îç∏)
        emotion_keywords = {
            "joy": ["Ï¢ã", "ÌñâÎ≥µ", "Ï¶êÍ±∞", "Ïû¨ÎØ∏", "ÏõÉ", "Í∏∞ÏÅ®"],
            "sadness": ["Ïä¨ÌîÑ", "Ïö∞Ïö∏", "ÎààÎ¨º", "ÏïÑÏâΩ", "ÏïàÌÉÄ"],
            "anger": ["Ìôî", "ÏßúÏ¶ù", "Î∂ÑÎÖ∏", "Ïó¥Î∞õ", "ÏñµÏö∏"],
            "surprise": ["ÎÜÄ", "Ï∂©Í≤©", "Î∞òÏ†Ñ", "ÏòàÏÉÅ", "ÏùòÏô∏"],
            "fear": ["Î¨¥ÏÑ≠", "Í≥µÌè¨", "ÎëêÎ†µ", "Í∏¥Ïû•"],
            "disgust": ["Ïó≠Í≤π", "Î∂àÏæå", "Ïã´"],
        }
        
        results = {}
        
        for emotion, keywords in emotion_keywords.items():
            count = sum(1 for keyword in keywords if keyword in text)
            # Ï†ïÍ∑úÌôî
            score = min(count / 3.0, 1.0)  # ÏµúÎåÄ 1.0
            results[emotion] = score
        
        return results


# Ïã±Í∏ÄÌÜ§ Ïù∏Ïä§ÌÑ¥Ïä§
_sentiment_analyzer = None
_absa_analyzer = None
_emotion_classifier = None


def get_sentiment_analyzer() -> SentimentAnalyzer:
    """Í∞êÏÑ± Î∂ÑÏÑùÍ∏∞ Ïã±Í∏ÄÌÜ§"""
    global _sentiment_analyzer
    if _sentiment_analyzer is None:
        _sentiment_analyzer = SentimentAnalyzer()
    return _sentiment_analyzer


def get_absa_analyzer() -> AspectBasedSentimentAnalyzer:
    """ABSA Î∂ÑÏÑùÍ∏∞ Ïã±Í∏ÄÌÜ§"""
    global _absa_analyzer
    if _absa_analyzer is None:
        _absa_analyzer = AspectBasedSentimentAnalyzer()
    return _absa_analyzer


def get_emotion_classifier() -> EmotionClassifier:
    """Í∞êÏ†ï Î∂ÑÎ•òÍ∏∞ Ïã±Í∏ÄÌÜ§"""
    global _emotion_classifier
    if _emotion_classifier is None:
        _emotion_classifier = EmotionClassifier()
    return _emotion_classifier
